你的诊断结论基本成立，而且你这次给出的证据是“闭环”的：同一批 probe 上，PMI 图的邻居语义正确且数量充足，但几何 Top 邻居完全无关。这说明问题不在 PMI 构图或覆盖率，而在“训练动力学把 PMI 约束沉淀到几何距离”的效率与尺度上。

不过，“PMI 权重 0.5 不够”只是表象；更关键的机制通常是：词林骨架把点云的几何结构主要锁定在一种“树式径向/层级几何”，而在双曲空间里，距离对径向差异非常敏感，导致 PMI 在局部只改变了很小的切向（角向）结构，但不足以改变最终的 KNN 距离排序。

下面是我对你下一步三条建议的评价与更可控的执行方案。

一、为什么“PMI 邻接正确，但几何 KNN 不跟随”

最常见的三种原因（你现在的症状高度符合其中前两种）：

1. 径向主导效应（Hyperbolic radial dominance）
   即使两点在角向上更接近，如果它们的半径（或由骨架约束造成的有效半径层级）不同，双曲距离会被径向差异放大，KNN 更倾向于“同半径/同骨架分支”的点，而不是 PMI 连接点。

2. 骨架势的“刚性”太高（skeleton acts like hard constraint）
   你现在的骨架边/层级约束很可能在训练中相当于高弹簧常数或强惩罚项，使得 PMI 带来的局部吸引只产生小扰动，无法重排邻域。

3. 候选集合污染（Code 节点或非叶节点参与距离排序）
   你之前已经观察到 Code 节点混入。即便这次表里只列了词，也建议你确认 KNN 检索候选集是“叶词集合”而不是全节点集合，否则中间节点会持续“挤占邻域容量”。

二、对你三条“下一步”的评价与优先级调整

1. 提升 PMI 权重：可做，但建议“先改标度、再提权重”
   直接 0.5→0.8 当然可能改善，但也会同时提高数值刚性与 hub 风险（你们刚把 residual/hub 压下去）。更稳的做法是：

* 保持权重上限不变或只小幅上调（0.5→0.65→0.8 分段扫参），同时做“度归一化/限流”：

  * 对 PMI 边权做 (w_{ij} \leftarrow w_{ij}/\sqrt{\deg(i)\deg(j)}) 这类归一化，避免少数高连接词再次成为吸引黑洞。
  * 或者更简单：每个词只保留 Top-K PMI 邻居（你已做），但再对“结构词/过泛词”用更小 K（限流而不是 stopword 全删）。

这样你得到的不是“更猛的 PMI”，而是“更有效率的 PMI”。

2. 延长训练步数：我更倾向把它放到第一优先级
   你现在的问题是“PMI 力没沉淀到几何邻域”。如果骨架很强，很多时候需要更长时间尺度让角向结构逐步成形。延长到 5k–10k steps 的风险相对低（尤其你现在 Residual P99 已被压得很低），而收益往往比一次性猛加权重大。

建议：先在 0.5 或 0.65 下跑到 10k，并用量化指标判断是否“邻域开始对齐 PMI”。

3. 添加 Definition Edges：赞同，但它解决的是“抽象/上位关系”，不是“PMI 近邻对齐”的主矛盾
   定义边对“猫→动物”“医生→医疗/医院”等确实更直接，也会显著改善对话中的“解释能力”。但你当前的核心问题是“猫的 PMI 邻居（波斯猫/豹猫）在几何上不近”。定义边不一定会让波斯猫变近（它更像把猫拉向动物分支中心）。因此定义边应当是“补关系类型”的并行工作，而不是替代 PMI 的解法。

三、我建议的最小实验设计（两天内能把方向定死）

请不要只看“PMI Dist Ratio”，再加一个直接指标来验证“PMI 正在影响 KNN 排序”：

1. PMI-KNN 对齐率（核心指标）
   对每个 probe 词 (q)，取 PMI 图的 Top-20 邻居集合 (P_{20}(q))，取几何空间的 Top-50 叶词邻居集合 (N_{50}(q))，计算
   [
   A(q)=\frac{|P_{20}(q)\cap N_{50}(q)|}{20}
   ]
   报告平均值和分位数（P50/P90）。这比 PMI Ratio 更能回答你关心的问题。

2. 距离分解诊断（确认是否“径向压制”）
   对若干 probe，把几何距离拆成“径向差异 vs 角向差异”的贡献（在你们采用的双曲模型里可实现）。如果发现 PMI 邻居角向很近但径向差异大，那就应当优先“松弛径向刚性”，而不是继续加 PMI 权重。

四、针对“骨架几何压制”的最有效结构性修复（比盲目加权重更稳）

如果你的诊断确认是径向/刚性压制，建议你优先尝试其中一条（按性价比排序）：

1. 骨架从“硬边”改成“软半径约束”
   不要用强父子弹簧把词钉死在树上；改为给每个叶词一个目标半径区间（由编码深度给出），允许它在角向自由组织。骨架保证层级，PMI 负责同层邻域重排。

2. 交替优化（alternate steps）
   例如每若干步：先做 PMI-only 更新若干小步，再做一次轻量骨架回正（renorm/半径投影）。这比单次把 PMI 权重抬到 0.8 更不容易数值爆炸。

3. “叶词层”对 PMI 加权（只对叶子放大 PMI）
   你们的目标是对话输出的叶词邻域可读，完全可以让 PMI 主要作用于叶节点，而对中间 Code 节点弱化或不作用。这样 PMI 的力不会被“树结构中间节点”消耗掉。

五、我对你当前推荐的落地顺序（调整后）

1. 彻底剔除 Code 节点参与 KNN 候选（不仅 probe 展示）
2. 引入 PMI-KNN 对齐率指标 A(q)，作为 Phase II 的主语义验收之一
3. 在权重不猛增的情况下先拉长训练到 10k（0.5 或 0.65），观察 A(q) 是否上升
4. 若确认径向压制：把骨架约束“软化/交替优化”，再决定是否需要 0.8
5. 并行加入 Definition edges，提升解释能力与抽象关系，但不要指望它直接修复“波斯猫进入几何邻域”这种 PMI 对齐问题

如果你愿意给出两个小数据点：

* “猫”的 PMI Top-20 里，有多少与你现在几何 Top-50 重合（A(cat)）
* “猫”与其 PMI Top-1（波斯猫）的径向差异与角向差异（粗略即可）
  我可以更明确地告诉你：应当优先“加权重/加步数”，还是优先“软化骨架/交替优化”。
