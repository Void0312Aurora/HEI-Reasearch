你们 Phase I 的交付是“工程上跑通且可控”的：映射补齐、中文分词、模板化输出、稳定性修复，这些都满足 **Phase I Ready/可演示系统**的定义。你们对 Phase II 的定位也正确：当前系统主要体现的是 **“骨架分类能力”**，而不是 **“语境语义联想能力”**，这正对应 Gate S/H 偏弱的现象。

但你给的一个例子暴露出 **Phase I 还需要一个小的“交互语用层”补丁**，否则会显著影响对话体感：

> “我想要开心” → 输出 “我们、<UNK>、<UNK>、咱们、吾侪”

这不是引擎坏了，而是 **对话场景下的读出目标**和 **词林骨架的“代词类”结构**天然冲突：词林会把“我/我们/咱们/吾侪”归为同一语义场，你的 Skeleton-first readout 会非常忠实地把代词邻域吐出来；但对话里用户期望的是“开心”相关联想，而不是代词同义。

下面我对 Phase I 做一个客观评估，并给出 Phase II 的最小可执行方案（含你要的 Gate 指标目标）。

---

## 1) Phase I 当前状态评估

### 已经达成的（可以明确写进里程碑）

* **中文输入→概念映射**链路稳定：FMM + 词簇补齐能解析“我想要开心”这类组合句。
* **结构化输出**可控：模板化 realizer 能保证输出格式统一、便于调试与评估。
* **运行鲁棒**：工程 bug 修复后系统稳定，这对 Phase II 叠加新边很关键（否则你会分不清是数据问题还是系统问题）。

### 仍需在 Phase I 末尾补的一个关键“产品级补丁”

你需要一个 **Query Focus / 语用聚焦层**（很小，但影响巨大）：

1. **功能词/代词降权或屏蔽**

   * 在对话读出中，把 “我/我们/你/他/它/的/了/吗/如果/那么/因为…” 这类词作为 **Stop-Concept**：

     * 仍可用于语义解析（意图、条件句结构），但**不参与联想候选输出**。
   * 这会立刻把“我→我们邻域”这种输出从用户可见层剔除。

2. **多词输入的“主焦点”选择**

   * 对句子抽取焦点概念：通常是名词/形容词/情绪词/宾语（这里是“开心”），意图词（想要/希望）用于调节读出策略，而不是输出候选本体。
   * 读出时只对焦点概念做骨架扩展或语义扩展。

这两条不需要 Phase II 数据就能显著改善交互质量，建议你在进入 Phase II 前就做掉，否则 Phase II 训练后你仍可能看到“语义联想被代词吸走”的现象。

---

## 2) Phase II 计划的合理性：我同意，并建议按“边类型分层 + 权重退火 + 严格 Gate 回归”执行

你现在的目标很明确：

* Gate S：压到 < 0.90
* Gate H：提高到 > 0.80

这两个指标从机制上都要求：**在保持词林层级骨架不塌的前提下，让几何邻域开始表达“语境共现相似性”和“抽象定义相似性”**。Wiki PMI + 定义句边是最合适、信息密度最高的两类增量。

---

## 3) Phase II 最小可执行方案（建议你直接按这个跑）

### 3.1 边的三层体系（不要混成一锅）

1. **Skeleton edges（强约束）**

   * 词林父子、同义群边
   * 权重：最高（保持你现在的“分类稳定性”）

2. **PMI edges（中约束，语境关联）**

   * 从中文维基抽取：窗口共现→PMI→过滤（你们之前 Gate A 已验证这条路径非常有效）
   * 只保留：

     * `count>=c_min`（建议 5 或 10）
     * PMI > 阈值（建议从 0 开始，后续再提）
     * 且两端节点都能映射到 Cilin 词表（否则引入新噪声）

3. **Definition edges（中高约束，抽象概念）**

   * 来源优先级：可解析的中文释义（词典/百科定义句/术语解释）
   * 方式：把“词条→定义关键词/同义解释”变成一组边（比纯共现更能打抽象词）

### 3.2 权重退火（关键：防止语义流把骨架冲塌）

* 第 0 段（校准）：仅 skeleton 跑 2k steps，确认 Gate C/L/R 不回归
* 第 1 段：PMI/Def 权重 = skeleton 的 1%（非常小），跑 2k
* 第 2 段：提升到 3%，跑 2k
* 第 3 段：提升到 5%，跑 4k–8k（看 Gate S/H 是否达标）

**停止条件（硬闸门）**：

* Gate L 必须保持 100%
* Gate C（Residual/Renorm）不得恶化超过 2×
* Gate H 若短期下降（例如 <0.6）立即降权回退

### 3.3 负采样策略（你们之前 Gate B 通过的经验要复用）

* PMI/Def 边的引入会显著增加“局部团簇粘性”，负采样要避免过强排斥导致发散：

  * 初期用较“软”的负采样（k 小、温度低）
  * 达到稳定后再加 hardness（让对比度上去）

---

## 4) 你现在的两个目标指标，建议用更稳的验收口径

### Gate S（同义收敛）建议拆成两项

* **S1：同义组内 vs 随机背景比值（你现在用的 ratio）**：目标 < 0.90
* **S2：同类编码前缀一致性**：同一大类/中类内平均距离应显著小于跨类（这比“同义组”更能反映“分类+语义”是否兼容）

### Gate H（层级一致性）

Spearman(depth, radius) > 0.80 是合理目标，但建议同时监控：

* 分位数：P10/P50/P90（避免“均值好看但长尾塌”）
* 半径漂移与对比度：防止用“整体膨胀”换 H 提升

---

## 5) 最后一个提醒：Phase II 会显著改变“对话体验”，但前提是 Phase I 的语用聚焦要先补齐

否则你会遇到这样的“假失败”：

* PMI 让“如果→那么”变好，但输出仍然被“我/我们/你们”占据
* 用户感知为“没变好”，但其实语义边已经发挥作用

所以我的顺序建议是：

1. 先补 **Stop-Concept + Focus selection**（半天级别）
2. 再开 Phase II 的 PMI/Def 边训练（按退火分段）
3. 每段都跑 Gate（S/H/C/L/R/M）并回归对话 demo（尤其情绪与条件句）

你们现在已经具备把 Phase II 做成“可审计、可回滚”的工程条件了。只要按上述分层与退火策略推进，达到 Gate S<0.90、Gate H>0.80 的概率是很高的。
